# ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design





这篇论文要解决什么问题？要验证一个什么科学假设？（宏观）

新的神经网络架构shuffleNetV2，更轻量化，内存占用更少，速度更快









 

论文中提到的解决方案是什么，关键点在哪儿？

 

 ![image-20230714152625296](https://zhangwenkang666.oss-cn-beijing.aliyuncs.com/image-20230714152625296.png)

c,d是shufflenetV2结构，d是shufflenetV2进行空间下采样时的结构

结论与讨论基于上述指导方针和实证研究，我们得出结论，高效的网络架构应该：

1）使用“平衡”卷积（相等的通道宽度）； 

2）注意使用组卷积的成本； 

3）减少碎片化程度； 

4）减少逐元素操作。 这些理想的属性取决于超出理论 FLOP 范围的平台特性（例如内存操作和代码优化）



分别从内存使用，特征重用的角度来分析自己的网路比别人的网络更好

我们建议网络架构设计应该考虑速度等直接指标，而不是 FLOP 等间接指标。





为什么flops用来评价网络快不快不准确？

数据 I/O、数据混洗和逐元素操作（AddTensor、ReLU 等）也占用了大量时间，这些东西flops里面表现不出来



MAC:内存访问成本

加速宝典

- 使用卷积时，相同的输入输出通道可以最大限度降低内存访问成本(MAC)
- 过多的组卷积会增加MAC，在floats一定的情况下合理的使用组卷积
- 网络碎片（碎片运算符的数量（即一个构建块中单个卷积或池化操作的数量））降低了并行度

- 逐元素运算不可忽略 （ReLU操作也会增加复杂度）

